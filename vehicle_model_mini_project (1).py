# -*- coding: utf-8 -*-
"""vehicle_model_mini_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z8fx0FyqIzUZ3p8bMQKlfCz2-KAVPd8h
"""

import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import kagglehub

# Download latest version
path = kagglehub.dataset_download("khwaishsaxena/vehicle-price-prediction-dataset")

print("Path to dataset files:", path)

df = pd.read_csv(f'{path}/Vehicle Price.csv')

"""# Data Analysis and Preprocessing"""

df.head()

df.describe()

df.info()

df.shape

"""check null values"""

#check null values
null_counts = df.isnull().sum()

print(null_counts)

# Impute missing values in categorical columns
df['description'] = df['description'].fillna('NoDetails')

df['exterior_color'] = df['exterior_color'].fillna('not provided')

df['interior_color'] = df['interior_color'].fillna('not provided')

df['engine'] = df['engine'].fillna('not provided')

df['transmission'] = df['transmission'].fillna('not provided')



df['doors'] = df['doors'].fillna(0)

df['body'] = df['body'].fillna(0)

df['trim'] = df['trim'].fillna(0)

#check null values
null_counts = df.isnull().sum()

print(null_counts)

# drop null values in price and fuel columns
df = df.dropna(subset=['price', 'fuel'])

null_counts = df.isnull().sum()

print(null_counts)

#fill missing values in cylinders and mileage with median
df['cylinders'] = df['cylinders'].fillna(df['cylinders'].median())
df['mileage'] = df['mileage'].fillna(df['mileage'].median())

print(df.isnull().sum())

# check duplicate values
print("Duplicate rows:", df.duplicated().sum())

#Remove duplicate values

df = df.drop_duplicates()

print("Duplicate rows:", df.duplicated().sum())

#Histogram for price
sns.histplot(df['price'], kde=True)
plt.show()

#boxplot of cylinders
sns.boxplot(x=df['cylinders'])
plt.show()

#Scatter plot
sns.scatterplot(x='mileage', y='price', data=df, hue='fuel')
plt.show()
sns.scatterplot(x='year', y='price', data=df)
plt.show()

#Heat Map
sns.heatmap(df[['price','mileage','cylinders','doors','year']].corr(), annot=True, cmap='coolwarm')
plt.show()

x=df['fuel']
y=df['mileage']
plt.figure(figsize=(9, 6))
plt.bar(x,y, color='m')
plt.xlabel('Fuel')
plt.ylabel('Mileage')
plt.title('Fuel vs Mileage')
plt.xticks(rotation=90)
plt.show()

#Prepare numeric matrix for PCA

PCA_Input = [c for c in ['year', 'cylinders', 'mileage', 'doors'] if c in df.columns]
X = df[PCA_Input].copy()

#f any remaining NaNs in the numeric inputs, fill with median
X = X.fillna(X.median())

#Standardize numeric inputs
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder

Scaler_PCA = StandardScaler()
X_pca_scaled = Scaler_PCA.fit_transform(X)

#Run PCA to reduce to 2 components
from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_pca_scaled)

#Attach PCA columns back to df for plotting/analysis
df['Vehicle_Feature_1'] = X_pca[:, 0]
df['Vehicle_Feature_2'] = X_pca[:, 1]

#Print explained variance
print("PCA explained variance ratio (PC1, PC2):", pca.explained_variance_ratio_)

# visual of PCA
plt.figure(figsize=(8,6))
sns.scatterplot(x='Vehicle_Feature_1', y='Vehicle_Feature_2', data=df, hue='fuel', s=60, alpha=0.7)
plt.title('PCA (2 components) colored by fuel type')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

df = df.drop(columns=['Vehicle_Feature_1', 'Vehicle_Feature_1'])

#Select only numeric columns before correlation
numeric_df = df.select_dtypes(include=['int64', 'float64'])
corr_matrix = numeric_df.corr()
print(corr_matrix)

#Heatmap for numeric correlations
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10,8))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap (Numeric Columns Only)')
plt.show()

#Correlation with a target column (price)
corr_with_price = numeric_df.corr()['price'].sort_values(ascending=False)
print(corr_with_price)

# --- 3. Price vs Year ---
plt.figure()
sns.boxplot(x='year', y='price', data=df)
plt.title("Price vs Year")
plt.show()

# --- 4. Price vs Mileage ---
plt.figure()
sns.scatterplot(x='mileage', y='price', data=df, alpha=0.5)
plt.title("Price vs Mileage")
plt.xlabel("Mileage")
plt.ylabel("Price")
plt.show()

# --- 6. Price by Fuel Type ---
plt.figure()
sns.boxplot(x='fuel', y='price', data=df)
plt.title("Price by Fuel Type")
plt.show()

# --- 5. Top 10 Makes by Count ---
top_makes = df['make'].value_counts().nlargest(10).index
plt.figure()
sns.boxplot(x='make', y='price', data=df[df['make'].isin(top_makes)])
plt.xticks(rotation=45)
plt.title("Price Distribution by Top 10 Makes")
plt.show()

from sklearn.preprocessing import OneHotEncoder

# List of categorical columns
categorical_cols = ['make', 'model', 'fuel', 'transmission',
                    'body', 'engine', 'trim', 'exterior_color',
                    'interior_color', 'drivetrain' ,]

# Convert all categorical columns to string type
df[categorical_cols] = df[categorical_cols].astype(str)

# Initialize encoder
encoder = OneHotEncoder(sparse_output=False, drop='first')

# Fit and transform categorical columns
encoded_data = encoder.fit_transform(df[categorical_cols])

# Convert encoded data to DataFrame
encoded_df = pd.DataFrame(encoded_data,
                          columns=encoder.get_feature_names_out(categorical_cols),
                          index=df.index)

# Drop original categorical columns and concatenate encoded columns
df_encoded = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)

# Check the result
print(df_encoded.head())

features = ['year', 'mileage', 'model', 'fuel']
X = df[features].copy()
y = df['price'].copy()

categorical_cols = ['model', 'fuel']
encoder = OneHotEncoder(sparse_output=False, drop='first')
X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]),
                         columns=encoder.get_feature_names_out(categorical_cols),
                         index=X.index)

# Combine numeric and encoded columns
numeric_cols = ['year', 'mileage']
X_final = pd.concat([X[numeric_cols], X_encoded], axis=1)

# Split data into train/test using the numeric-only X_final
from sklearn.model_selection import train_test_split
train_data, test_data, train_target, test_target = train_test_split(
    X_final, y, test_size=0.2, random_state=42
)


print(test_target,test_target.shape)

print(test_data,test_data.shape)

"""# Linear Regression"""

# Train model with linear regression algorithm

from sklearn.linear_model import LinearRegression

model_1 = LinearRegression()
model_1.fit(train_data, train_target)

predicted_target=model_1.predict(test_data)
print('Predicted Target: ',predicted_target)

"""**Linear Regressor sample check**"""

sample_input = pd.DataFrame({
    'year': [2010],
    'mileage': [200.0],
    'model': ['Wagoneer'],
    'fuel': ['Gasoline']
})

# Encode sample input using the same fitted encoder
sample_encoded = encoder.transform(sample_input[['model', 'fuel']])
sample_encoded_df = pd.DataFrame(sample_encoded,
                                 columns=encoder.get_feature_names_out(['model','fuel']))

# Combine numeric columns with encoded categorical columns
sample_final = pd.concat([sample_input[['year', 'mileage']].reset_index(drop=True),
                          sample_encoded_df], axis=1)

# Align columns with training data
sample_final = sample_final.reindex(columns=X_final.columns, fill_value=0)

# Predict
predicted_price = model_1.predict(sample_final)
print("Predicted Price:", predicted_price[0])

print(X_final.columns)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

MAE = mean_absolute_error(test_target, predicted_target)
MSE = mean_squared_error(test_target, predicted_target)
RMSE = np.sqrt(MSE)
R2_score = r2_score(test_target, predicted_target)

print('Mean Absoulte Error:', MAE)
print('Mean Squared Error:', MSE)
print('RMSE:', RMSE)
print('R² score:', R2_score)

"""# Decision Tree Regressor"""

#model train with  Decision Tree Regressor

from sklearn.tree import DecisionTreeRegressor

model_2 = DecisionTreeRegressor(random_state=42)
model_2.fit(train_data, train_target)

predicted_target=model_2.predict(test_data)

print('Predicted Target: ',predicted_target)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Predict on test set
predicted_target = model_2.predict(test_data)

# Evaluate model
MAE = mean_absolute_error(test_target, predicted_target)
MSE = mean_squared_error(test_target, predicted_target)
RMSE = np.sqrt(MSE)
R2 = r2_score(test_target, predicted_target)

print("Mean Absoulte Error:", MAE)
print("Mean Squared Error:", MSE)
print("RMSE:", RMSE)
print("R² score:", R2)

"""**Decision Tree sample check**"""

sample_input = pd.DataFrame({
    'year': [2024],
    'mileage': [1.0],
    'model': ['Wagoneer'],
    'fuel': ['Gasoline']
})

# # Step 1: Fit the encoder on the training data (model and fuel columns)
# encoder = OneHotEncoder(sparse_output=False, drop='first')  # Corrected parameter

# # Assuming `train_data` contains the categorical columns `model` and `fuel`
# encoder.fit(train_data[['model', 'fuel']])  # Fit encoder to the training data

# # Step 2: Encode sample input using the fitted encoder
# sample_input = pd.DataFrame({
#     'year': [2024],
#     'mileage': [1.0],
#     'model': ['Wagoneer'],
#     'fuel': ['Gasoline']
# })

# # Encode the categorical features of the sample input
# sample_encoded = encoder.transform(sample_input[['model', 'fuel']])

# # Convert encoded sample to DataFrame
# sample_encoded_df = pd.DataFrame(sample_encoded,
#                                  columns=encoder.get_feature_names_out(['model', 'fuel']))

# # Combine numeric columns with encoded categorical columns
# sample_final = pd.concat([sample_input[['year', 'mileage']].reset_index(drop=True),
#                           sample_encoded_df], axis=1)

# # Align columns with training data
# sample_final = sample_final.reindex(columns=X_final.columns, fill_value=0)

# # Step 3: Predict the price using the trained model
# predicted_price = model_2.predict(sample_final)

# # Output the predicted price
# print("Predicted Price:", predicted_price[0])

df.head()

# Importing necessary libraries
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Splitting the dataset into training and testing sets
from sklearn.model_selection import train_test_split
train_data, test_data, train_target, test_target = train_test_split(X_final, y, test_size=0.2, random_state=42)

# Training the Decision Tree model
model_2 = DecisionTreeRegressor(random_state=42)
model_2.fit(train_data, train_target)

# Predicting the target (price) for the test data
predicted_target = model_2.predict(test_data)

# Evaluating the model's performance
MAE = mean_absolute_error(test_target, predicted_target)
MSE = mean_squared_error(test_target, predicted_target)
RMSE = np.sqrt(MSE)
R2 = r2_score(test_target, predicted_target)

# Output the results
print("Mean Absolute Error:", MAE)
print("Mean Squared Error:", MSE)
print("RMSE:", RMSE)
print("R² score:", R2)

# Step 1: Fit the encoder on the original data (model and fuel columns)
encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
encoder.fit(X[['model', 'fuel']])  # Fit encoder on categorical columns in the original X

# Split data into train/test using the numeric-only X and the target y
from sklearn.model_selection import train_test_split
train_data, test_data, train_target, test_target = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 2: Transform the sample input using the fitted encoder
sample_input = pd.DataFrame({
    'year': [2023],
    'mileage': [32.0],
    'model': ['Durango'],
    'fuel': ['Gasoline']
})

# Encode the categorical features of the sample input
sample_encoded = encoder.transform(sample_input[['model', 'fuel']])

# Convert encoded sample to DataFrame
sample_encoded_df = pd.DataFrame(sample_encoded,
                                 columns=encoder.get_feature_names_out(['model', 'fuel']))

# Combine numeric columns with encoded categorical columns
sample_final = pd.concat([sample_input[['year', 'mileage']].reset_index(drop=True),
                          sample_encoded_df], axis=1)

# Align columns with the training data (same as X_final)
sample_final = sample_final.reindex(columns=X_final.columns, fill_value=0)

# Step 3: Predict the price using the trained model
predicted_price = model_2.predict(sample_final)
print("Predicted Price for the vehicle:", predicted_price[0])

df.head()

import pickle

# model_2 is the trained model
with open('decision_tree_model.pkl', 'wb') as file:
    pickle.dump(model_2, file)

print("Model saved as decision_tree_model.pkl")